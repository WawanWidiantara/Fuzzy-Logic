# -*- coding: utf-8 -*-
"""Fuzzy_CMeans_k2&3.py

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17eSFF_55rZOvoxPZ3GhlAPyaO1TUPz51

# Kluster 2
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt


class FuzzyCMeans:
    def __init__(
        self,
        n_clusters=5,
        m=3,
        max_iter=100,
        tolerance=0.00001,
        random_state=42,
        init=None,
    ):
        """
        Initializes the Fuzzy C-Means clustering algorithm.

        Args:
            n_clusters (int): The number of clusters to form.
            m (float): The fuzziness parameter (m > 1). Controls the degree of fuzziness in cluster assignments.
            max_iter (int): The maximum number of iterations.
            tolerance (float): Convergence threshold based on changes in the membership matrix.
            random_state (int, optional): Seed for random number generation. Using a seed ensures same initialization across runs. Defaults to None.
        """

        self.n_clusters = n_clusters
        self.m = m
        self.max_iter = max_iter
        self.tolerance = tolerance
        self.random_state = random_state
        self.centroids = None  # Cluster centroids
        self.init_u = None  # Initial membership matrix
        self.U = init  # Membership matrix

    def fit(self, data):
        """
        Fits the Fuzzy C-Means model to the data.

        Args:
            data (numpy.ndarray): The input data.
        """

        # Set the random seed for reproducibility
        rng = np.random.default_rng(self.random_state)
        if self.U is None:
            self.U = rng.random((data.shape[0], self.n_clusters))
            self.U /= np.sum(self.U, axis=1)[:, np.newaxis]
            self.init_u = self.U.copy()
        self.init_u = self.U.copy()

        # Lists to store centroids and U values at each iteration
        self.centroid_history = []
        self.u_history = []

        for _ in range(self.max_iter):
            self.centroids = self._calculate_centroids(data)
            new_u = self._calculate_membership(data)

            # Store the centroids and U values
            self.centroid_history.append(self.centroids.copy())
            self.u_history.append(new_u.copy())

            if np.linalg.norm(new_u - self.U) <= self.tolerance:
                break

            self.U = new_u

    def get_centroid_history(self):
        """
        Returns the history of centroids across iterations.

        Returns:
            list: A list of numpy arrays, where each array represents centroids at an iteration.
        """
        return self.centroid_history

    def get_u_history(self):
        """
        Returns the history of membership matrices (U values) across iterations.

        Returns:
            list: A list of numpy arrays, where each array represents the membership matrix at an iteration.
        """
        return self.u_history

    def get_initial_u(self):
        """
        Returns the initial membership matrix.

        Returns:
            numpy.ndarray: The initial membership matrix (U).
        """
        return self.init_u

    def predict(self, data):
        """
        Predicts cluster assignments for new data points.

        Args:
            data (numpy.ndarray): The new data.

        Returns:
            numpy.ndarray: Cluster labels for each data point.
        """

        if self.centroids is None:
            raise ValueError("FCM model not fitted. Call fit() first.")
        return np.argmax(self._calculate_membership(data), axis=1)

    def _calculate_centroids(self, data):
        """
        Calculates cluster centroids based on current membership degrees.

        Args:
            data (numpy.ndarray): The input data.

        Returns:
            numpy.ndarray: Updated cluster centroids.
        """

        weighted_sum = np.dot((self.U**self.m).T, data)
        membership_sums = np.sum(self.U**self.m, axis=0)
        return weighted_sum / membership_sums[:, np.newaxis]

    def _calculate_membership(self, data):
        """
        Calculates membership degrees of data points to each cluster.

        Args:
            data (numpy.ndarray): The input data.

        Returns:
            numpy.ndarray: The membership matrix.
        """

        distances = np.linalg.norm(data[:, np.newaxis] - self.centroids, axis=2)
        distances[distances == 0] = np.finfo(float).eps

        inv_distances = 1 / (distances ** (2 / (self.m - 1)))
        return inv_distances / inv_distances.sum(axis=1)[:, np.newaxis]


if __name__ == "__main__":
    # Load the data
    raw_data = pd.read_excel(r"/content/data-facial-wash.xlsx")
    raw_data = raw_data.drop(["Merk_Produk"], axis=1)
    data = raw_data.to_numpy()

    # Set hyperparameters
    n_clusters = 2
    max_iter = 1000
    m = 2
    error = 0.0001
    initial_u = [
        [0.3166187 , 0.6833813 ],
       [0.7573433 , 0.2426567 ],
       [0.88227539, 0.11772461],
       [0.46664779, 0.53335221],
       [0.2617011 , 0.7382989 ],
       [0.56106526, 0.43893474],
       [0.1049842 , 0.8950158 ],
       [0.96181449, 0.03818551],
       [0.39797465, 0.60202535],
       [0.73234804, 0.26765196],
       [0.03013364, 0.96986636],
       [0.75678372, 0.24321628],
       [0.61547954, 0.38452046],
       [0.27974347, 0.72025653],
       [0.49586902, 0.50413098],
       [0.15906872, 0.84093128],
       [0.28186888, 0.71813112],
       [0.35837767, 0.64162233],
       [0.32556076, 0.67443924],
       [0.32754426, 0.67245574],
       [0.39893204, 0.60106796],
       [0.61185177, 0.38814823],
       [0.59850068, 0.40149932],
       [0.89011544, 0.10988456],
       [0.58365728, 0.41634272],
       [0.66888767, 0.33111233],
       [0.42391531, 0.57608469],
       [0.3829078 , 0.6170922 ],
       [0.62414097, 0.37585903],
       [0.14188318, 0.85811682],
       [0.52818921, 0.47181079],
       [0.54751976, 0.45248024],
       [0.07500917, 0.92499083],
       [0.92715653, 0.07284347],
       [0.49455706, 0.50544294],
    ]
    initial_u = np.array(initial_u)

    # Initialize and fit the FCM model
    fcm = FuzzyCMeans(
        n_clusters=n_clusters, m=m, max_iter=max_iter, tolerance=error, init=initial_u
    )

    fcm.fit(data)
    initial_u = fcm.get_initial_u()
    print(initial_u)

    # Predict cluster labels
    labels = fcm.predict(data)
    print(labels)

"""# Kluster 3"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt


class FuzzyCMeans:
    def __init__(
        self,
        n_clusters=5,
        m=3,
        max_iter=100,
        tolerance=0.00001,
        random_state=42,
        init=None,
    ):
        """
        Initializes the Fuzzy C-Means clustering algorithm.

        Args:
            n_clusters (int): The number of clusters to form.
            m (float): The fuzziness parameter (m > 1). Controls the degree of fuzziness in cluster assignments.
            max_iter (int): The maximum number of iterations.
            tolerance (float): Convergence threshold based on changes in the membership matrix.
            random_state (int, optional): Seed for random number generation. Using a seed ensures same initialization across runs. Defaults to None.
        """

        self.n_clusters = n_clusters
        self.m = m
        self.max_iter = max_iter
        self.tolerance = tolerance
        self.random_state = random_state
        self.centroids = None  # Cluster centroids
        self.init_u = None  # Initial membership matrix
        self.U = init  # Membership matrix

    def fit(self, data):
        """
        Fits the Fuzzy C-Means model to the data.

        Args:
            data (numpy.ndarray): The input data.
        """

        # Set the random seed for reproducibility
        rng = np.random.default_rng(self.random_state)
        if self.U is None:
            self.U = rng.random((data.shape[0], self.n_clusters))
            self.U /= np.sum(self.U, axis=1)[:, np.newaxis]
            self.init_u = self.U.copy()
        self.init_u = self.U.copy()

        # Lists to store centroids and U values at each iteration
        self.centroid_history = []
        self.u_history = []

        for _ in range(self.max_iter):
            self.centroids = self._calculate_centroids(data)
            new_u = self._calculate_membership(data)

            # Store the centroids and U values
            self.centroid_history.append(self.centroids.copy())
            self.u_history.append(new_u.copy())

            if np.linalg.norm(new_u - self.U) <= self.tolerance:
                break

            self.U = new_u

    def get_centroid_history(self):
        """
        Returns the history of centroids across iterations.

        Returns:
            list: A list of numpy arrays, where each array represents centroids at an iteration.
        """
        return self.centroid_history

    def get_u_history(self):
        """
        Returns the history of membership matrices (U values) across iterations.

        Returns:
            list: A list of numpy arrays, where each array represents the membership matrix at an iteration.
        """
        return self.u_history

    def get_initial_u(self):
        """
        Returns the initial membership matrix.

        Returns:
            numpy.ndarray: The initial membership matrix (U).
        """
        return self.init_u

    def predict(self, data):
        """
        Predicts cluster assignments for new data points.

        Args:
            data (numpy.ndarray): The new data.

        Returns:
            numpy.ndarray: Cluster labels for each data point.
        """

        if self.centroids is None:
            raise ValueError("FCM model not fitted. Call fit() first.")
        return np.argmax(self._calculate_membership(data), axis=1)

    def _calculate_centroids(self, data):
        """
        Calculates cluster centroids based on current membership degrees.

        Args:
            data (numpy.ndarray): The input data.

        Returns:
            numpy.ndarray: Updated cluster centroids.
        """

        weighted_sum = np.dot((self.U**self.m).T, data)
        membership_sums = np.sum(self.U**self.m, axis=0)
        return weighted_sum / membership_sums[:, np.newaxis]

    def _calculate_membership(self, data):
        """
        Calculates membership degrees of data points to each cluster.

        Args:
            data (numpy.ndarray): The input data.

        Returns:
            numpy.ndarray: The membership matrix.
        """

        distances = np.linalg.norm(data[:, np.newaxis] - self.centroids, axis=2)
        distances[distances == 0] = np.finfo(float).eps

        inv_distances = 1 / (distances ** (2 / (self.m - 1)))
        return inv_distances / inv_distances.sum(axis=1)[:, np.newaxis]


if __name__ == "__main__":
    # Load the data
    raw_data = pd.read_excel(r"/content/data-facial-wash.xlsx")
    raw_data = raw_data.drop(["Merk_Produk"], axis=1)
    data = raw_data.to_numpy()

    # Set hyperparameters
    n_clusters = 3
    max_iter = 1000
    m = 2
    error = 0.0001
    initial_u = [
        [0.19156277, 0.41346394, 0.39497329],
       [0.65384161, 0.20949422, 0.13666417],
       [0.87644194, 0.11694624, 0.00661182],
       [0.28529923, 0.326081  , 0.38861977],
       [0.1197354 , 0.33779192, 0.54247267],
       [0.15490401, 0.1211851 , 0.72391089],
       [0.04385221, 0.37385079, 0.582297  ],
       [0.88874191, 0.03528442, 0.07597368],
       [0.32164088, 0.48655351, 0.19180561],
       [0.65397473, 0.23900879, 0.10701648],
       [0.01331287, 0.42848138, 0.55820575],
       [0.50916066, 0.16363481, 0.32720452],
       [0.49449824, 0.30893747, 0.19656428],
       [0.25812924, 0.66460629, 0.07726447],
       [0.26831228, 0.27278278, 0.45890494],
       [0.12407518, 0.65593471, 0.21999011],
       [0.1681843 , 0.42849135, 0.40332435],
       [0.24966849, 0.44699458, 0.30333694],
       [0.19509843, 0.40417045, 0.40073112],
       [0.21392766, 0.43919829, 0.34687405],
       [0.37007499, 0.55758926, 0.07233575],
       [0.14820362, 0.09401782, 0.75777856],
       [0.23391922, 0.15692281, 0.60915798],
       [0.37657984, 0.0464887 , 0.57693147],
       [0.29378996, 0.20957043, 0.49663961],
       [0.47082811, 0.23306902, 0.29610286],
       [0.20092845, 0.27305408, 0.52601747],
       [0.29044376, 0.46807763, 0.24147861],
       [0.60786216, 0.3660559 , 0.02608195],
       [0.10671476, 0.64541644, 0.2478688 ],
       [0.51414083, 0.45926192, 0.02659726],
       [0.17990457, 0.1486764 , 0.67141903],
       [0.05505361, 0.67890478, 0.26604161],
       [0.6193742 , 0.04866208, 0.33196371],
       [0.33762349, 0.34505505, 0.31732145],
    ]
    initial_u = np.array(initial_u)

    # Initialize and fit the FCM model
    fcm = FuzzyCMeans(
        n_clusters=n_clusters, m=m, max_iter=max_iter, tolerance=error, init=initial_u
    )

    fcm.fit(data)
    initial_u = fcm.get_initial_u()
    print(initial_u)

    # Predict cluster labels
    labels = fcm.predict(data)
    print(labels)